{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cafef3d-06dc-475f-a876-20dad96c2cff",
   "metadata": {},
   "source": [
    "# X-CLIP : Video to Text Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d766b3ad-1fac-430b-b518-77c6f08171dd",
   "metadata": {},
   "source": [
    "## XCLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b27bc9-f6ae-47a6-8219-a9b739bda56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A video of action, abuse',\n",
       " 'A video of action, arrest',\n",
       " 'A video of action, arson',\n",
       " 'A video of action, assault',\n",
       " 'A video of action, burglary',\n",
       " 'A video of action, explosion',\n",
       " 'A video of action, fighting',\n",
       " 'A video of action, road accident',\n",
       " 'A video of action, robbery',\n",
       " 'A video of action, shooting',\n",
       " 'A video of action, shoplifting',\n",
       " 'A video of action, stealing',\n",
       " 'A video of action, vandalism']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## clip_len = 8\n",
    "# model_name = \"microsoft/xclip-base-patch32\" # clip_len = 8\n",
    "# model_name = \"microsoft/xclip-base-patch16\" # clip_len = 8\n",
    "# model_name = \"microsoft/xclip-large-patch14\" # clip_len = 8\n",
    "\n",
    "## clip_len = 16\n",
    "# model_name = \"microsoft/xclip-base-patch32-16-frames\" # clip_len = 16\n",
    "model_name = \"microsoft/xclip-base-patch16-16-frames\" # clip_len = 16\n",
    "# model_name = \"microsoft/xclip-large-patch14-16-frames\" #  clip_len = 16\n",
    "\n",
    "## HMDB-51\n",
    "# model_name = \"microsoft/xclip-base-patch16-hmdb-2-shot\" # clip_len = 32\n",
    "# model_name = \"microsoft/xclip-base-patch16-hmdb-4-shot\" # clip_len = 32\n",
    "# model_name = \"microsoft/xclip-base-patch16-hmdb-8-shot\" # clip_len = 32\n",
    "# model_name = \"microsoft/xclip-base-patch16-hmdb-16-shot\" # clip_len = 32\n",
    "\n",
    "## UCF-101\n",
    "# model_name = \"microsoft/xclip-base-patch16-ucf-2-shot\" # clip_len = 32\n",
    "# model_name = \"microsoft/xclip-base-patch16-ucf-4-shot\" # clip_len = 32\n",
    "# model_name = \"microsoft/xclip-base-patch16-ucf-8-shot\" # clip_len = 32\n",
    "# model_name = \"microsoft/xclip-base-patch16-ucf-16-shot\" # clip_len = 32\n",
    "\n",
    "## Kinetics-400\n",
    "# model_name = \"microsoft/xclip-base-patch16-zero-shot\" # clip_len = 8\n",
    "\n",
    "## Kinetics-600\n",
    "# model_name = \"microsoft/xclip-base-patch16-kinetics-600\" # clip_len = 8\n",
    "# model_name = \"microsoft/xclip-large-patch14-kinetics-600\" # clip_len = 8\n",
    "# model_name = \"microsoft/xclip-base-patch16-kinetics-600-16-frames\" # clip_len = 16\n",
    "\n",
    "label = [\n",
    "    \"abuse\", \"arrest\", \"arson\", \"assault\", \"burglary\",\n",
    "    \"explosion\", \"fighting\", \"road accident\", \"robbery\", \"shooting\",\n",
    "    \"shoplifting\", \"stealing\", \"vandalism\"\n",
    "]\n",
    "\n",
    "label = list(map(lambda x : f\"A video of action, {x}\", label))\n",
    "\n",
    "clip_len = 16\n",
    "seed = 826\n",
    "\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53053865-93ca-4256-a6da-94ff809e305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "def read_video_pyav(container, indices):\n",
    "    '''\n",
    "    Decode the video with PyAV decoder.\n",
    "    Args:\n",
    "        container (`av.container.input.InputContainer`): PyAV container.\n",
    "        indices (`List[int]`): List of frame indices to decode.\n",
    "    Returns:\n",
    "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
    "    '''\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "\n",
    "def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n",
    "    '''\n",
    "    Sample a given number of frame indices from the video.\n",
    "    Args:\n",
    "        clip_len (`int`): Total number of frames to sample.\n",
    "        frame_sample_rate (`int`): Sample every n-th frame.\n",
    "        seg_len (`int`): Maximum allowed index of sample's last frame.\n",
    "    Returns:\n",
    "        indices (`List[int]`): List of sampled frame indices\n",
    "    '''\n",
    "    converted_len = int(clip_len * frame_sample_rate)\n",
    "    end_idx = np.random.randint(converted_len, seg_len)\n",
    "    start_idx = end_idx - converted_len\n",
    "    indices = np.linspace(start_idx, end_idx, num=clip_len)\n",
    "    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11987367-9d3e-47b5-88ef-e575df51ceee",
   "metadata": {},
   "source": [
    "### Abuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4caa728d-01a7-42fb-9011-dd88a3eae800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 170\n",
      "seg_len : 2729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taehyeong\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Unused or unrecognized kwargs: padding.\n",
      "C:\\Users\\Taehyeong\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\feature_extraction_utils.py:141: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  return torch.tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2072, 0.1117, 0.0448, 0.0172, 0.1716, 0.0355, 0.0190, 0.0550, 0.0914,\n",
      "         0.0627, 0.0495, 0.0668, 0.0678]])\n",
      "abuse true : 0\n",
      "abuse pred : 0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/Abuse001_x264.mp4\"\n",
    "# file_path = \"data/UCF-Crime_TH/Abuse001_x264_5s-15s.mp4\"\n",
    "# file_path = \"data/UCF-Crime_TH/Abuse001_x264_5s-15s_crop.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"abuse true : 0\")\n",
    "print(f\"abuse pred : {torch.argmax(probs).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73105745-29f6-43d5-b08b-9eafc8d7aa00",
   "metadata": {},
   "source": [
    "### Arrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89dbfa3-a770-40d3-9d1a-79a08e8bc0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 112\n",
      "seg_len : 1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0485, 0.1312, 0.0076, 0.0392, 0.0486, 0.0084, 0.0246, 0.0868, 0.1934,\n",
      "         0.0469, 0.3162, 0.0074, 0.0412]])\n",
      "arrest true : 1\n",
      "arrest pred : 10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/Arrest023_x264.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"arrest true : 1\")\n",
    "print(f\"arrest pred : {torch.argmax(probs).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbfa044-79b4-428b-9f14-1b870dcbbe4f",
   "metadata": {},
   "source": [
    "### Arson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe8c9b0-400f-4b75-bfda-561678cb6525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 277\n",
      "seg_len : 4439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0051, 0.1894, 0.1708, 0.0180, 0.1055, 0.0225, 0.0155, 0.0359, 0.0956,\n",
      "         0.0181, 0.0931, 0.0118, 0.2187]])\n",
      "arson true : 2\n",
      "arson pred : 12\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/Arson002_x264.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"arson true : 2\")\n",
    "print(f\"arson pred : {torch.argmax(probs).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b4f7f-5001-4f62-b50d-19082dcd063e",
   "metadata": {},
   "source": [
    "### Assault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "553c18cb-3afd-49b0-b5b7-3b764c9e513e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 157\n",
      "seg_len : 2523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0862, 0.5320, 0.0077, 0.0564, 0.0108, 0.0014, 0.0069, 0.0102, 0.0744,\n",
      "         0.0052, 0.1991, 0.0041, 0.0056]])\n",
      "assualt true : 3\n",
      "assualt pred : 1\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/Assault002_x264.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"assualt true : 3\")\n",
    "print(f\"assualt pred : {torch.argmax(probs).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c11895-3800-4b64-94b2-fd4d04b5e953",
   "metadata": {},
   "source": [
    "### Burglary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4686919f-17b1-422d-96f9-62164991afc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 73\n",
      "seg_len : 1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0217, 0.1391, 0.0221, 0.0143, 0.0749, 0.2172, 0.0723, 0.0747, 0.0420,\n",
      "         0.0612, 0.0381, 0.1763, 0.0462]])\n",
      "burglary true : 4\n",
      "burglary pred : 5\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/Burglary003_x264.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"burglary true : 4\")\n",
    "print(f\"burglary pred : {torch.argmax(probs).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0299837b-4648-459d-903d-9aa1279c87f2",
   "metadata": {},
   "source": [
    "### Explosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e181708c-07d5-4fd4-adf3-7d46ae4ff764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 35\n",
      "seg_len : 576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0098, 0.0266, 0.0051, 0.0045, 0.0035, 0.0067, 0.0123, 0.8523, 0.0114,\n",
      "         0.0154, 0.0345, 0.0056, 0.0123]])\n",
      "explosion true : 5\n",
      "explosion pred : 7\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/Explosion003_x264.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"explosion true : 5\")\n",
    "print(f\"explosion pred : {torch.argmax(probs).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c7778e-0ce2-4ca6-a32f-edb345886643",
   "metadata": {},
   "source": [
    "### Fighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1cb42db-920c-400a-a18d-3ed6aff20835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 1048\n",
      "seg_len : 16777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1926, 0.3968, 0.0158, 0.1336, 0.0446, 0.0075, 0.0157, 0.0064, 0.0325,\n",
      "         0.0293, 0.1014, 0.0167, 0.0071]])\n",
      "fighting true : 6\n",
      "fighting pred : 1\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/Fighting004_x264.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"fighting true : 6\")\n",
    "print(f\"fighting pred : {torch.argmax(probs).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91a62ec-1e4a-421a-b50e-36d239e58862",
   "metadata": {},
   "source": [
    "### Road Accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49a7db68-999a-4992-902b-93a17bcfa886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 57\n",
      "seg_len : 918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0766, 0.0292, 0.0179, 0.0348, 0.0336, 0.0792, 0.0272, 0.2805, 0.0070,\n",
      "         0.0104, 0.0187, 0.0147, 0.3701]])\n",
      "road accident true : 7\n",
      "road accident pred : 12\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/RoadAccidents009_x264.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"road accident true : 7\")\n",
    "print(f\"road accident pred : {torch.argmax(probs).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b841e1-0c3b-487b-a01f-8e8149a07fd1",
   "metadata": {},
   "source": [
    "### Robbery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7e7bf8d-6e98-4ae7-b30a-cb393922c36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 95\n",
      "seg_len : 1529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9307e-03, 2.3960e-02, 8.9805e-04, 1.6033e-02, 2.0826e-02, 4.7560e-04,\n",
      "         1.5415e-03, 6.3453e-04, 5.0097e-01, 7.7569e-04, 4.1898e-01, 8.5359e-03,\n",
      "         4.4376e-03]])\n",
      "robbery true : 8\n",
      "robbery pred : 8\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/Robbery004_x264.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"robbery true : 8\")\n",
    "print(f\"robbery pred : {torch.argmax(probs).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a408c-f1f3-4e07-bd5a-70eefdaefde3",
   "metadata": {},
   "source": [
    "### Shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d37645e4-7932-41a1-a13f-2b7bbba93c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 15\n",
      "seg_len : 253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0397, 0.0452, 0.0048, 0.0844, 0.0203, 0.0041, 0.0151, 0.0104, 0.0505,\n",
      "         0.0048, 0.7141, 0.0014, 0.0052]])\n",
      "shooting true : 9\n",
      "shooting pred : 10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/Shooting001_x264.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"shooting true : 9\")\n",
    "print(f\"shooting pred : {torch.argmax(probs).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d49d0-78f6-4e92-a17e-63e4f1986de0",
   "metadata": {},
   "source": [
    "### Shoplifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07794971-f327-4098-84f2-82d4a2897e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 271\n",
      "seg_len : 4344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0089, 0.0119, 0.0029, 0.0050, 0.0328, 0.0058, 0.0030, 0.0057, 0.0587,\n",
      "         0.0150, 0.8334, 0.0148, 0.0019]])\n",
      "shoplifting true : 10\n",
      "shoplifting pred : 10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/Shoplifting001_x264.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"shoplifting true : 10\")\n",
    "print(f\"shoplifting pred : {torch.argmax(probs).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d1e7c0-74e9-4a95-ac71-da911f49abaa",
   "metadata": {},
   "source": [
    "### Stealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c77133f-6a53-49e8-8715-82967b010954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 201\n",
      "seg_len : 3223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0422, 0.0324, 0.0026, 0.0094, 0.0848, 0.0014, 0.0146, 0.6209, 0.0260,\n",
      "         0.0168, 0.0803, 0.0090, 0.0598]])\n",
      "stealing true : 11\n",
      "stealing pred : 7\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/Stealing006_x264.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"stealing true : 11\")\n",
    "print(f\"stealing pred : {torch.argmax(probs).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2fd2ef-eda1-457d-85d1-df86a2d1d181",
   "metadata": {},
   "source": [
    "### Vandalism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc203405-045f-4cc5-aa34-4701cbf69f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_sample_rate : 176\n",
      "seg_len : 2820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0113, 0.0233, 0.0034, 0.0066, 0.0362, 0.0077, 0.0220, 0.3574, 0.1210,\n",
      "         0.0249, 0.0708, 0.0649, 0.2503]])\n",
      "vandalism true : 12\n",
      "vandalism pred : 7\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = \"data/UCF-Crime/Vandalism004_x264.mp4\"\n",
    "container = av.open(file_path)\n",
    "\n",
    "frame_sample_rate = int((container.streams.video[0].frames-1) / clip_len)\n",
    "print(f\"frame_sample_rate : {frame_sample_rate}\")\n",
    "print(f\"seg_len : {container.streams.video[0].frames}\")\n",
    "\n",
    "# sample clip_len frames\n",
    "indices = sample_frame_indices(\n",
    "    clip_len=clip_len, frame_sample_rate=frame_sample_rate,\n",
    "    seg_len=container.streams.video[0].frames\n",
    ")\n",
    "video = read_video_pyav(container, indices)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(\n",
    "    text=label,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_video = outputs.logits_per_video  # this is the video-text similarity score\n",
    "probs = logits_per_video.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "print(probs)\n",
    "\n",
    "print(f\"vandalism true : 12\")\n",
    "print(f\"vandalism pred : {torch.argmax(probs).numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
